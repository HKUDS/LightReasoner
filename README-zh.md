<!-- Icon and title -->
<h1 align="center">
<img src="./assets/lr_logo2.png" width="100" alt="lightreasoner-logo" />
<br>
ğŸ’¡ LightReasoner: å°æ¨¡å‹èƒ½å¦æ•™ä¼šå¤§æ¨¡å‹æ¨ç†ï¼Ÿ
</h1>

<!-- Authors -->
<h3 align="center">
<a href="https://scholar.google.com/citations?user=BGT3Gb8AAAAJ&hl=en" target="_blank"> ç‹é–æº</a> Â·
<a href="https://scholar.google.com/citations?user=k6yAt6IAAAAJ&hl=en&oi=sra" target="_blank"> é™ˆè¨€æ¥·</a> Â·
<a href="https://scholar.google.com/citations?user=__9uvQkAAAAJ&hl=en" target="_blank"> æä¸­è¡Œ</a> Â·
<a href="https://scholar.google.com/citations?user=Zkv9FqwAAAAJ&hl=en" target="_blank"> é»„è¶…</a>
</h3>

<p align="center">
  <img src="./assets/welcome.png" width="500" alt="Welcome banner"/>
</p>

<!-- Quick links -->
<div align="center">

[![arXiv](https://img.shields.io/badge/arXiv-2510.07962-b31b1b.svg)](https://arxiv.org/abs/2510.07962)
[![ğŸ¤— Paper](https://img.shields.io/badge/ğŸ¤—_Paper-LightReasoner-ffcc4d.svg)](https://huggingface.co/papers/2510.07962)
[![License](https://img.shields.io/badge/Code%20License-MIT-green.svg)](https://opensource.org/licenses/MIT)
[![Baselines](https://img.shields.io/badge/Baselines-Qwen2.5--Math-blue.svg)](https://github.com/QwenLM/Qwen2.5-Math)
![](https://img.shields.io/badge/Python-3.10+-yellow.svg)
[![ğŸ¤— Models](https://img.shields.io/badge/ğŸ¤—_Models-LightReasoner_Models-ffcc4d.svg)](https://huggingface.co/collections/bearthecoder/lightreasoner-models-68edbf175755ca5a8c699f9c)
<img src="https://visitor-badge.laobi.icu/badge?page_id=HKUDS.LightReasoner&style=for-the-badge&color=00d4ff" alt="Visitors">

<br>

<a href="./Communication.md"><img src="https://img.shields.io/badge/ğŸ’¬é£ä¹¦-ç¾¤ç»„-07c160?style=for-the-badge&logoColor=white&labelColor=1a1a2e"></a>
<a href="./Communication.md"><img src="https://img.shields.io/badge/å¾®ä¿¡-ç¾¤ç»„-07c160?style=for-the-badge&logo=wechat&logoColor=white&labelColor=1a1a2e"></a>

</div>

---

<p align="center">
  <img src="./assets/lr_bars.png" width="800" />
  <br>
  <em><strong>å›¾ 1: LightReasoner ä»¥å“è¶Šçš„ Token æ•ˆç‡å®ç°æ›´ä¼˜æ€§èƒ½</strong> - åœ¨é›¶æ ·æœ¬ pass@1 å‡†ç¡®ç‡ä¸Šå®ç°æŒç»­æå‡ï¼ŒåŒæ—¶ç›¸è¾ƒäºä¼ ç»Ÿ SFTï¼Œæ€»æ—¶é—´è®¡ç®—å¼€é”€å‡å°‘ 90%ï¼Œé‡‡æ ·é—®é¢˜æ•°å‡å°‘ 80%ï¼Œè°ƒä¼˜ Token æ•°å‡å°‘ 99%ã€‚</em>
</p>

**ğŸ’¡ æ ¸å¿ƒæ´å¯Ÿï¼š**

è¿™ä¸€æ•ˆç‡çªç ´è¡¨æ˜ï¼Œ**ç­–ç•¥æ€§çš„ Token é€‰æ‹©**ï¼Œè€Œéç©·ä¸¾å¼çš„è®­ç»ƒï¼Œæ‰æ˜¯è§£é”å¤§è¯­è¨€æ¨¡å‹æ¨ç†æ½œåŠ›çš„æœ€æœ‰æ•ˆé€”å¾„ â€”â€” è¯æ˜äº†*æ›´æ™ºèƒ½ï¼Œè€Œéæ›´è›®å¹²*ï¼Œæ‰æ˜¯å®ç°å¯æ‰©å±• AI æå‡çš„é“è·¯ã€‚

---

## ğŸ‰ æœ€æ–°åŠ¨æ€
- [x] [2025/10/14] ğŸš€ æ–°å‘å¸ƒï¼š[`LRsamples`](./LRsamples) â€” **é¢„æ”¶é›†çš„ LightReasoner è®­ç»ƒæ ·æœ¬**ï¼Œå¯ç«‹å³ç”¨äºå¾®è°ƒã€‚æ­¤æ•°æ®é›†æ”¯æŒç›´æ¥æ¨¡å‹è®­ç»ƒï¼Œæ— éœ€è¿è¡Œå®Œæ•´çš„é‡‡æ ·æµç¨‹ï¼Œç®€åŒ–äº†å¤ç°å·¥ä½œå¹¶åŠ é€Ÿäº†ä¸‹æ¸¸ç ”ç©¶æµç¨‹ã€‚
- [x] [2025/10/14] ğŸš€ æ–°å‘å¸ƒï¼š**LightReasoner å¢å¼ºæ¨¡å‹** ç°å·²åœ¨ ğŸ¤— [Hugging Face Hub](https://huggingface.co/collections/bearthecoder/lightreasoner-models-68edbf175755ca5a8c699f9c) ä¸Šæä¾›ã€‚è¿™äº›å³ç”¨å‹æ¨¡å‹é‡‡ç”¨æˆ‘ä»¬é«˜æ•ˆçš„æ¨ç†å¢å¼ºæ–¹æ³•è¿›è¡Œäº†å¾®è°ƒï¼Œå¯ä¾›ç«‹å³éƒ¨ç½²å’Œå®éªŒã€‚
- [x] [2025/10/12] ğŸš€ æ–°å‘å¸ƒï¼šåŸºäº Qwen2.5-Math å’Œ DeepSeek æ¨¡å‹å®éªŒçš„æ ¸å¿ƒå®ç°ã€‚

---

## âš¡ å†…å®¹æè¦

**âœ¨ LightReasoner âœ¨** é¢ è¦†äº† AI è®­ç»ƒçš„å¸¸è§„è®¤çŸ¥ â€”â€” å°è¯­è¨€æ¨¡å‹ (SLM) ä¸ä»…ä»…å‘å¤§æ¨¡å‹ (LLM) *å­¦ä¹ *ï¼›å®ƒä»¬å®é™…ä¸Šå¯ä»¥æ›´å¥½ã€æ›´å¿«åœ°*æ•™å¯¼* LLMï¼

**ğŸ”¥ é¢ä¸´çš„æŒ‘æˆ˜ï¼š**

ç›‘ç£å¾®è°ƒ (SFT) é¢ä¸´ä¸‰ä¸ªæ ¸å¿ƒç“¶é¢ˆï¼š

- **ğŸ“Š æ•°æ®å¯†é›†å‹ï¼š** ä¾èµ–äººå·¥æ ‡æ³¨æˆ–æ‹’ç»é‡‡æ ·çš„æ•°æ®é›†ã€‚

- **âš–ï¸ å‡åŒ€å­¦ä¹ ï¼š** å¹³ç­‰åœ°è®­ç»ƒæ‰€æœ‰ Tokenï¼Œå°½ç®¡åªæœ‰ä¸€å°éƒ¨åˆ†çœŸæ­£é‡è¦ã€‚

- **ğŸ”— ä¾èµ–çœŸå®æ ‡ç­¾ï¼š** é˜»ç¢äº†åœ¨æ–°é¢†åŸŸå’Œæ¨ç†æ ¼å¼ä¸Šçš„é€‚åº”æ€§ã€‚

**ğŸ” æ ¸å¿ƒæ´å¯Ÿï¼š**

æˆ‘ä»¬å°† 90% çš„è®¡ç®—èµ„æºåˆ†é…ç»™äº†æ¨¡å‹å·²ç»æŒæ¡çš„çŸ¥è¯†ï¼Œè€Œå¯¹äºçœŸæ­£æ¨åŠ¨çªç ´çš„å…³é”® 10%ï¼Œå´*æŠ•å…¥ä¸è¶³*ã€‚

## ğŸ“ˆ LightReasonerï¼š*æ›´å¥½ã€æ›´å¿«*

**åœ¨ 7 ä¸ªåŸºå‡†æµ‹è¯• Ã— 5 ä¸ªæ¨¡å‹ä¸Šè¿›è¡ŒéªŒè¯**

ğŸš€ **æ€§èƒ½æå‡**

LightReasoner åœ¨å¤šä¸ªæ•°æ®é›†ä¸ŠæŒç»­æå‡æ¨ç†å‡†ç¡®ç‡ï¼š

- ğŸ“ˆ **Qwen2.5-Math-1.5B:** GSM8K ä¸Š +28.1%, MATH ä¸Š +25.1%, SVAMP ä¸Š +7.2%, ASDIV ä¸Š +11.7%

- ğŸ“ˆ **DeepSeek-R1-Distill-Qwen-1.5B:** GSM8K ä¸Š +4.3%, MATH ä¸Š +6.0%, OlympiadBench ä¸Š +17.4%

- ğŸ“ˆ **Qwen2.5-Math-7B:** GSM8K ä¸Š +10.4%, MATH ä¸Š +6.0%, SVAMP ä¸Š +9.3%, ASDIV ä¸Š +7.9%

- ğŸŒ **å¼ºå¤§çš„æ³›åŒ–èƒ½åŠ›ï¼š** ä»…åœ¨ GSM8K ä¸Šè®­ç»ƒï¼Œå´åœ¨ **7 ä¸ªåŸºå‡†æµ‹è¯•** ä¸Šå‡æœ‰æå‡

âš¡ **æ•ˆç‡çªç ´**

ä»¥ `Qwen2.5-Math-1.5B` ä¸ºä¾‹ï¼ŒLightReasoner ç›¸è¾ƒäº SFT å®ç°äº†æ˜¾è‘—çš„æ•ˆç‡æå‡ï¼š

- â±ï¸ **æ€»æ—¶é—´å‡å°‘ 90%:** 4 å°æ—¶ â†’ 0.5 å°æ—¶

- ğŸ§¾ **é‡‡æ ·é—®é¢˜å‡å°‘ 80%:** 3,952 â†’ 1,000 ä¸ªé—®é¢˜

- ğŸ”¢ **è°ƒä¼˜ Token å‡å°‘ 99%:** 1.77M â†’ 20K ä¸ª Token

ğŸŒŸ **æ ¸å¿ƒç‰¹æ€§**

- ğŸ¯ **SLMâ€“LLM æ•™å­¦ï¼š**

  åç›´è§‰åœ°ä½¿ç”¨è¾ƒå°çš„*"ä¸šä½™"*æ¨¡å‹æ¥è¯†åˆ«**å…³é”®æ¨ç†æ—¶åˆ»**ï¼Œè®©æ›´å¼ºçš„*"ä¸“å®¶"*æ¨¡å‹åœ¨è¿™äº›æ—¶åˆ»é›†ä¸­å­¦ä¹ ã€‚

- âš¡ **æè‡´çš„ Token æ•ˆç‡ï¼š**

  é€šè¿‡é€‰æ‹©æ€§åœ°ä¼˜åŒ–**é«˜å½±å“åŠ›çš„æ¨ç†æ­¥éª¤**ï¼Œè€Œéåœ¨å…¨è½¨è¿¹ä¸Šå‡åŒ€è®­ç»ƒï¼Œå®ç°äº†æ¯” SFT **å°‘ 99% çš„è°ƒä¼˜ Token**ã€‚

- ğŸ”„ **ä¸‰é˜¶æ®µè½»é‡çº§æ¡†æ¶ï¼š**

  (1) é€šè¿‡ä¸“å®¶-ä¸šä½™ KLD æ£€æµ‹è¿›è¡Œ**å…³é”®æ­¥éª¤é€‰æ‹©**

  (2) é€šè¿‡æ•æ‰ä¸“å®¶-ä¸šä½™è¡Œä¸ºå·®å¼‚è¿›è¡Œ**å¯¹æ¯”ç›‘ç£**

  (3) é€šè¿‡**è‡ªè’¸é¦**å†…åŒ–ä¸“å®¶ä¼˜åŠ¿

- ğŸ“ˆ **KL å¼•å¯¼å­¦ä¹ ï¼š**

  åˆ©ç”¨ä¸“å®¶å’Œä¸šä½™é¢„æµ‹ä¹‹é—´çš„**è¡Œä¸ºå·®å¼‚**æ¥**ç²¾ç¡®å®šä½æ¨ç†ç“¶é¢ˆ**â€”â€”*æ‰€æœ‰è¿™äº›éƒ½æ— éœ€çœŸå®æ ‡ç­¾ã€‚*

- ğŸ§  **ä¸“é•¿èƒœäºè§„æ¨¡ï¼š**

  è¯æ˜äº†**é¢†åŸŸä¸“é•¿å·®è·**ï¼Œè€Œéæ¨¡å‹å¤§å°ï¼Œæ˜¯é©±åŠ¨æœ‰æ•ˆå¯¹æ¯”çš„å…³é”® â€”â€” å³ä½¿æ˜¯ç›¸åŒå¤§å°ä½†çŸ¥è¯†ä¸åŒçš„æ¨¡å‹ä¹Ÿèƒ½äº§ç”Ÿ**å¼ºå¤§çš„æ•™å­¦ä¿¡å·**ã€‚

---

## ğŸ§© LightReasoner æ¡†æ¶

<p align="center">
  <img src="./assets/lr_new.png" width="800" />
  <br>
  <em>
    <strong>å›¾ 2: LightReasoner æ¡†æ¶æ¦‚è§ˆã€‚</strong> (1) é‡‡æ ·é˜¶æ®µï¼šä¸“å®¶å’Œä¸šä½™æ¨¡å‹ç”Ÿæˆåˆ†å¸ƒ Ï€<sub>E</sub> å’Œ Ï€<sub>A</sub>ã€‚ä¿¡æ¯æ€§æ­¥éª¤é€‰æ‹©ä¿ç•™ D<sub>KL</sub>(Ï€<sub>E</sub> âˆ¥ Ï€<sub>A</sub>) > Î² çš„æ­¥éª¤ï¼Œå¯¹æ¯”ç›‘ç£é€šè¿‡ä¸“å®¶-ä¸šä½™å¯¹æ¯”æ„å»ºè½¯æ ‡ç­¾ v<sub>C</sub> ä»¥æ•æ‰ä¸“å®¶çš„ä¼˜åŠ¿ã€‚(2) å¾®è°ƒé˜¶æ®µï¼šé€šè¿‡æœ€å°åŒ–ä¸“å®¶æ¨¡å‹è¾“å‡ºä¸ v<sub>C</sub> ä¹‹é—´çš„ KL æ•£åº¦æ¥å¢å¼ºä¸“å®¶æ¨¡å‹ã€‚
  </em>
</p>

---

## ğŸš€ å¿«é€Ÿå¼€å§‹

*LightReasoner* ä½¿ç”¨èµ·æ¥*æå…¶ç®€å•*ã€‚æˆ‘ä»¬å°†å…¶è®¾è®¡å¾—éå¸¸æ˜“äºä¸Šæ‰‹ â€”â€” ä»»ä½•äººéƒ½å¯ä»¥å°è¯•å¹¶äº²èº«ä½“éªŒå…¶"åç›´è§‰çš„æœ‰æ•ˆæ€§"ã€‚
åˆ«æ‹…å¿ƒ â€”â€” åªéœ€æŒ‰ç…§ä¸‹é¢å‡ ä¸ª ğŸª„ ç®€å•çš„æ­¥éª¤ï¼Œæ‚¨å°±å¯ä»¥è®¾ç½®å¹¶è¿è¡Œæ‚¨é€‰æ‹©çš„æ¨¡å‹ï¼

### ğŸ“¦ å‡†å¤‡å·¥ä½œ
```bash
git clone https://github.com/HKUDS/LightReasoner.git
cd LightReasoner
```

1ï¸âƒ£ å®‰è£…æ‰€æœ‰ä¾èµ–:

```bash
pip install -r requirements.txt
```

2ï¸âƒ£ ä¸‹è½½æ‚¨é€‰æ‹©çš„ä¸“å®¶å’Œä¸šä½™æ¨¡å‹ã€‚ä¾‹å¦‚:

ğŸ¦‰ ä¸“å®¶æ¨¡å‹
```bash
huggingface-cli download Qwen/Qwen2.5-Math-1.5B --local-dir ./Qwen2.5-Math-1.5B
```

ğŸ£ ä¸šä½™æ¨¡å‹
```bash
huggingface-cli download Qwen/Qwen2.5-0.5B --local-dir ./Qwen2.5-0.5B
```


3ï¸âƒ£ å‡†å¤‡è®­ç»ƒæ•°æ®ï¼š

```bash
python data_prep.py
```


#### âš ï¸ æ³¨æ„äº‹é¡¹

LightReasoner ä¾èµ–ä¸“å®¶-ä¸šä½™æ¨¡å‹é…å¯¹æ¥ç”Ÿæˆç›‘ç£ä¿¡å·ã€‚å› æ­¤ï¼Œè¿™å¯¹æ¨¡å‹çš„é€‰æ‹©å¯¹äºæ–¹æ³•çš„æˆåŠŸè‡³å…³é‡è¦ã€‚

âš–ï¸ **ç»éªŒæ³•åˆ™**: 

ä¸“å®¶æ¨¡å‹åº”**æ˜¾è‘—ä¼˜äº**ä¸šä½™æ¨¡å‹ï¼Œè€Œä¸šä½™æ¨¡å‹å¿…é¡»ä¿æŒ**è¶³å¤Ÿçš„èƒ½åŠ›**ä»¥äº§ç”Ÿè¿è´¯çš„æ¨ç†ã€‚åœ¨å®è·µä¸­ï¼Œæ€§èƒ½åœ¨å¹³è¡¡çš„ *â€œæœ€ä½³ç‚¹â€* è¾¾åˆ°å³°å€¼ï¼Œè€Œä¸æ˜¯ç®€å•åœ°æ‰©å¤§èƒ½åŠ›å·®è·ã€‚

åœ¨æˆ‘ä»¬çš„å®éªŒä¸­ï¼Œä¸“å®¶æ¨¡å‹åŒ…æ‹¬ *Qwen2.5-Math-1.5B*ã€7Bã€å®ƒä»¬çš„ Instruct ç‰ˆæœ¬ä»¥åŠ *DeepSeek-R1-Distill* å˜ä½“ã€‚ä¸šä½™æ¨¡å‹å›ºå®šä¸º *Qwen2.5-0.5B*ï¼Œå®ƒåœ¨æä¾›å¼ºçƒˆå¯¹æ¯”çš„åŒæ—¶ï¼Œä¿æŒäº†è¶³å¤Ÿçš„æ¨ç†èƒ½åŠ›ä»¥äº§ç”Ÿæœ‰æ„ä¹‰çš„ä¿¡å·ã€‚

æˆ‘ä»¬ *é¼“åŠ±* æ‚¨æ¢ç´¢å…¶ä»–æ¨¡å‹ç³»åˆ—ï¼ˆä¾‹å¦‚ *Llama*ï¼‰ï¼Œä½†åœ¨è®¾ç½®æ‚¨çš„ä¸“å®¶-ä¸šä½™åä½œæ—¶ï¼Œè¯·ç‰¢è®°æ­¤**å¹³è¡¡åŸåˆ™**ã€‚


#### ğŸ“‹ è¯´æ˜

- æˆ‘ä»¬ *é»˜è®¤* ä½¿ç”¨ GSM8Kï¼Œå› ä¸ºå®ƒä¾§é‡äºæ­¥éª¤æ¸…æ™°ã€å¹¿æ³›é€‚ç”¨çš„é€»è¾‘æ¨ç†ï¼Œè€Œéç‰¹å®šé¢†åŸŸçš„ç¬¦å·ã€‚è¿™ç¡®ä¿äº†ä¸šä½™æ¨¡å‹å³ä½¿ç¼ºä¹æ•°å­¦ä¸“é¡¹è®­ç»ƒï¼Œä»èƒ½äº§ç”Ÿé€‚åˆå¯¹æ¯”ç›‘ç£çš„å¯è§£é‡Šè¾“å‡ºã€‚

æ‚¨ *å®Œå…¨å¯ä»¥* å°è¯•å…¶ä»–æ•°æ®é›† â€”â€” LightReasoner å®Œå…¨é€‚é…ã€‚ä½†æ˜¯ï¼Œæ ¹æ®æ‚¨çš„æ•°æ®é›†ï¼Œæ‚¨å¯èƒ½éœ€è¦è°ƒæ•´è¶…å‚æ•°å’Œä¸šä½™æ¨¡å‹çš„é€‰æ‹©ï¼Œä»¥ç¡®ä¿è®­ç»ƒç¨³å®šå’Œå¯¹æ¯”æœ‰æ„ä¹‰ã€‚


---


### ğŸ¯ é‡‡æ ·

æ­¤æ­¥éª¤æ„å»ºç”¨äºä¸‹æ¸¸å¾®è°ƒçš„ **LightReasoner ç›‘ç£æ•°æ®é›†**ã€‚ä¿ç•™å…·æœ‰é«˜ä¸“å®¶-ä¸šä½™ KLD çš„æ­¥éª¤ã€‚è¿™äº›é€‰å®šçš„æ­¥éª¤è¢«è½¬æ¢ä¸ºç›‘ç£æ ·æœ¬ï¼Œé€šè¿‡åˆ†å¸ƒå¯¹æ¯”æ¥ç¼–ç ä¸“å®¶çš„ä¼˜åŠ¿ã€‚æœ‰å…³å®Œæ•´ç»†èŠ‚ï¼Œè¯·å‚é˜… [æˆ‘ä»¬çš„è®ºæ–‡](https://arxiv.org/abs/2510.07962).


```bash
python LightR_sampling.py --max_questions 1000
```


#### ğŸ“‹ è¯´æ˜
åœ¨è¿è¡Œè„šæœ¬ä¹‹å‰ï¼Œæ‚¨åº”è¯¥ï¼š

ä½¿ç”¨æ‚¨è‡ªå·±çš„ç›¸å…³è·¯å¾„æ›´æ–° **é…ç½®éƒ¨åˆ†**ã€‚

è°ƒæ•´æœ€å¤§é—®é¢˜æ•°ä»¥æ§åˆ¶ç›‘ç£æ•°æ®é›†çš„å¤§å°ï¼Œè°ƒæ•´é‡‡æ ·å‚æ•°ä»¥æ¢ç´¢æ›´ä¼˜ç»„åˆï¼Œå¹¶æ ¹æ®å¯ç”¨çš„è®¡ç®—èµ„æºè°ƒæ•´æ‰¹æ¬¡å¤§å°ã€‚


#### âš¡ **æ·å¾„**


ä¸ºäº†çœå»è¿è¡Œé‡‡æ ·æµç¨‹çš„éº»çƒ¦ â€”â€” å°½ç®¡ä½¿ç”¨ LightReasoner å·²ç» *æ›´è½»é‡ã€æ›´å®¹æ˜“*ï¼Œä½†å¯¹äºè®¡ç®—èµ„æºä¸å……è¶³çš„ç”¨æˆ·æ¥è¯´å¯èƒ½ä»ç„¶ä»¤äººç”Ÿç• â€”â€” æˆ‘ä»¬ç°åœ¨æä¾› *å³ç”¨å‹çš„* LightReasoner æ ·æœ¬ï¼Œ**è®©æ‚¨ç›´æ¥è·³åˆ°å¾®è°ƒé˜¶æ®µï¼** ğŸš€  


 

æ‚¨å¯ä»¥åœ¨ [`LRsamples`](./LRsamples) ç›®å½•ä¸‹çš„ zip æ–‡ä»¶ä¸­æ‰¾åˆ°ä»¥ä¸‹é¢„æ”¶é›†çš„ LightReasoner é‡‡æ ·æ•°æ®é›†ï¼š

- **`LR_Qwen7_gsm8k`** â€” é€‚ç”¨äº **Qwen2.5-Math-7B**

- **`LR_ds1.5_gsm8k`** â€” é€‚ç”¨äº **DeepSeek-R1-Distill-Qwen-1.5B**

- **`LR_Qwen1.5_gsm8k`** â€” é€‚ç”¨äº **Qwen2.5-Math-1.5B** 

- We provide **two versions**, one sampled with **Torch 3.1** and another with **Torch 3.8**, as we found that the sampling results (i.e., the modelâ€™s generated outputs) can slightly vary across Torch versions.  

- The performance fluctuation is minimal â€” typically within **2â€“3%**, with later Torch versions usually performing slightly better.

These datasets make it **much easier to reproduce** our results directly â€” no additional sampling required! âœ¨





æ‚¨å¯ä»¥åœ¨ LRsamples ç›®å½•ä¸‹çš„ zip æ–‡ä»¶ä¸­æ‰¾åˆ°ä»¥ä¸‹é¢„æ”¶é›†çš„ LightReasoner é‡‡æ ·æ•°æ®é›†ï¼š

LR_Qwen7_gsm8k â€” é€‚ç”¨äº Qwen2.5-Math-7B

LR_ds1.5_gsm8k â€” é€‚ç”¨äº DeepSeek-R1-Distill-Qwen-1.5B

LR_Qwen1.5_gsm8k â€” é€‚ç”¨äº Qwen2.5-Math-1.5B

æˆ‘ä»¬æä¾›äº†ä¸¤ä¸ªç‰ˆæœ¬ï¼Œä¸€ä¸ªä½¿ç”¨ Torch 3.1 é‡‡æ ·ï¼Œå¦ä¸€ä¸ªä½¿ç”¨ Torch 3.8 é‡‡æ ·ï¼Œå› ä¸ºæˆ‘ä»¬å‘ç°é‡‡æ ·ç»“æœï¼ˆå³æ¨¡å‹ç”Ÿæˆçš„è¾“å‡ºï¼‰åœ¨ä¸åŒ Torch ç‰ˆæœ¬é—´å¯èƒ½ç•¥æœ‰ä¸åŒã€‚

æ€§èƒ½æ³¢åŠ¨å¾ˆå° â€”â€” é€šå¸¸åœ¨ 2â€“3% ä»¥å†…ï¼Œè¾ƒæ–°çš„ Torch ç‰ˆæœ¬é€šå¸¸è¡¨ç°ç¨å¥½ã€‚

è¿™äº›æ•°æ®é›†ä½¿å¾—ç›´æ¥å¤ç°æˆ‘ä»¬çš„ç»“æœå®¹æ˜“å¾—å¤šâ€”â€” æ— éœ€é¢å¤–é‡‡æ ·ï¼âœ¨










---


### âš™ï¸ Fine-tuning

This step launches the full LightReasoner fine-tuning pipeline â€” combining *dataset loading*, *LoRA configuration*, and *contrastive KLD training* into a unified workflow.


#### ğŸ’» Run Options

**Foreground (simple run):**
```bash
python LightR_finetuning.py
```

**Background (recommended for long training):**
```bash
nohup python LightR_finetuning.py > finetune.log 2>&1 &
```

**Monitor progress:**
```bash
tail -f finetune.log
```


#### âš ï¸ Caveat

*The expert model used for fine-tuning must be identical to the one used during sampling â€” this alignment is essential for correct behavior.*


#### ğŸ“‹ Note

Before running the script, edit the **config section** to match your setup:

- ğŸ”¹ Replace `<path_to_expert_model>` with your base model path *(e.g., `"./Qwen2.5-Math-7B"` or a local folder).*  

- ğŸ”¹ Replace `<path_to_training_dataset>` with your dataset JSONL file.  

- ğŸ”¹ Replace `<output_directory>` with the directory where checkpoints and the final model will be saved.  

- ğŸ”¹ Set `torch_dtype` according to your hardware *(e.g., `torch.bfloat16` for **H100**, `torch.float16` for **A100**).*


---


### ğŸ”— Model Merging

Use this step to **merge the full model** (base + LoRA) locally, so it behaves as a **standalone model** without any LoRA dependency.

```bash
python merge.py
```

#### ğŸ“‹ Note
Before running the merge script, update the **config section** with your own paths: 

- ğŸ”¹ `base_model_path` to your base model directory *(e.g., `./Qwen2.5-Math-7B`)* 

- ğŸ”¹ `lora_ckpt_path` to your LoRA checkpoint directory *(e.g., `./ft_qw7_gsm8k/checkpoint-1000`)*  

- ğŸ”¹ `merged_model_path` to where you want the merged model to be saved *(e.g., `./ft-7B-merged`)*


---


### ğŸ“ˆ Evaluation

All evaluations are performed using the **official Qwen2.5-Math toolkit**.  

Please refer to the [`evaluation`](./evaluation) folder for detailed usage and setup instructions.


---


## ğŸ“Š Main Results

| Model                                         | GSM8K | MATH | SVAMP | ASDiv | Minerva Math | Olympiad Bench | MMLU STEM | AVG. |
|-----------------------------------------------|-------|------|-------|-------|-------------------|---------------|----------------|------|
| **<nobr>Qwen2.5-Math-1.5B</nobr>**            |       |      |       |       |                   |               |                |      |
| Baseline                                      | 42.5  | 34.2 | 68.8  | 68.1  | 9.9               | 23.7          | 49.8           | 42.4 |
| + SFT                                         | 69.2  | 57.1 | 64.1  | 70.2  | **15.1**          | **27.6**      | 47.7           | 50.1 |
| + LightR                                      | **70.6** | **59.3** | **76.0** | **79.8** | 11.4 | 27.1 | **54.9** | **54.2** |
| **<nobr>Qwen2.5-Math-1.5B-Instruct</nobr>**   |       |      |       |       |                   |               |                |      |
| Baseline                                      | 84.8  | 75.8 | 94.2  | 94.7  | 29.4              | 37.5          | 57.4           | 67.7 |
| + SFT                                         | 85.4  | 75.8 | 93.5  | 94.7  | 31.6              | 37.5          | 56.2           | 67.8 |
| + LightR                                      | **86.7** | 75.5 | 93.0 | 94.1 | **32.0** | **37.8** | 55.2 | **67.8** |
| **<nobr>DeepSeek-R1-Distill-Qwen-1.5B</nobr>**|       |      |       |       |                   |               |                |      |
| Baseline                                      | 75.2  | 54.2 | 79.9  | 84.9  | 16.2              | 19.1          | 22.3           | 50.3 |
| + SFT                                         | 78.2  | **60.3** | 81.5 | 87.4 | **18.4** | 21.2 | 26.2 | 53.3 |
| + LightR                                      | **79.5** | 60.2 | **83.5** | **87.5** | 18.0 | **36.5** | **26.2** | **55.9** |
| **<nobr>Qwen2.5-Math-7B</nobr>**              |       |      |       |       |                   |               |                |      |
| Baseline                                      | 57.5  | 51.8 | 67.9  | 72.7  | 14.0              | 16.0          | 69.8           | 50.0 |
| + SFT                                         | 64.4  | **63.3** | 76.2 | 76.6 | 12.1 | **20.5** | 68.5 | 54.5 |
| + LightR                                      | **67.9** | 57.8 | **77.2** | **80.6** | 12.1 | 16.9 | **70.5** | **54.7** |
| **<nobr>Qwen2.5-Math-7B-Instruct</nobr>**     |       |      |       |       |                   |               |                |      |
| Baseline                                      | 95.2  | 83.2 | 93.9  | 95.3  | 33.8              | 41.5          | 69.3           | 73.2 |
| + SFT                                         | 95.4  | 83.1 | **94.1** | 95.2 | **38.2** | 40.7 | 68.2 | **73.6** |
| + LightR                                      | **95.8** | **83.6** | 93.1 | 95.2 | 34.2 | 39.0 | 67.8 | 72.7 |


- Trained *solely* on GSM8K, LightReasoner generalizes effectively for 5 baseline models, achieving consistent gains across 7 benchmarks.

- **+28.1%** on GSM8K, **+25.1%** on MATH, **+7.2%** on SVAMP, **+11.7%** on ASDIV for Qwen2.5-Math-1.5B.  

- **+4.3%** on GSM8K, **+6.0%** on MATH, **+17.4%** on OlympiadBench for DeepSeek-R1-Distill-Qwen-1.5B. 

- **+10.4%** on GSM8K, **+6.0%** on MATH, **+9.3%** on SVAMP, **+7.9%** on ASDIV for Qwen2.5-Math-7B.  

- Efficiency vs. SFT: **90% less total time**, **80% fewer sampled problems**, **99% fewer tuned tokens**.  


---


## â±ï¸ Efficiency Study

| **Method** | **Total Time** | **Sampled Problems** | **Tuned Tokens** | **Average Gain** |
|------------|----------|------------|------------|----------|
| **Qwen2.5-Math-1.5B** |||||
| + SFT      | 4.0h     | 3952       | 1.77M      | +7.7%   |
| **+ LightReasoner** | **0.5h** | **1000**  | **0.02M**  | **+11.8%** |
| **Qwen2.5-Math-7B** |||||
| + SFT      | 9.5h     | 6029       | 2.20M      | +4.5%   |
| **+ LightReasoner** | **0.75h** | **1000** | **0.02M**  | **+4.7%** |
| **DeepSeek-R1-Distill-Qwen-1.5B** |||||
| + SFT     | 3.6h     | 6023       | 5.95M      | +3.0%   |
| **+ LightReasoner** | **0.5h** | **1000**  | **0.02M**  | **+5.6%** |
| **Qwen2.5-Math-1.5B-Instruct** |||||
| + SFT     | 3.4h     | 7153       | 2.08M      | +0.1%   |
| **+ LightReasoner** | **0.4h** | **1000**  | **0.02M**  | +0.1%   |


- ğŸ§‘â€ğŸ« **Supervised Fine-Tuning (SFT):**  
  - Implemented with rejection sampling, where models are fine-tuned on demonstrations of correct reasoning trajectories.  
  
  - For a fair comparison, SFT adopts the *same* experimental configuration as LightReasoner, performing LoRA-based fine-tuning *exclusively* on the GSM8K training set.


- ğŸ“ˆ **Efficiency Evaluation:**  
  - â±ï¸ **Time Budget** â€” Sampling time plus fine-tuning time, measured on a single *NVIDIA H200 GPU* without inference accelerators (e.g., vLLM).  
  
  - ğŸ“˜ **Training Instances** â€” Number of distinct GSM8K training set problems used to generate the supervision dataset.  
  
  - ğŸ”¢ **Tuned Tokens** â€” Computational overhead at the token level: *LightReasoner* trains on selective next-token predictions, whereas *SFT* optimizes over full reasoning trajectories.


<p align="center">
  <img src="./assets/radar_1.5B.png" width="200" />
  <img src="./assets/radar_7B.png" width="200" />
  <img src="./assets/radar_ds1.5B.png" width="200" />
  <img src="./assets/radar_1.5Bins.png" width="196" />
  <br>
  <em><strong>Figure 3: LightReasoner matches or surpasses SFT performance with remarkable resource efficiency</strong> â€” achieving competitive accuracy while cutting training time by 90%, reducing sampled problems by 80%, and requiring 99% fewer tuned tokens.</em>

</p>


ğŸ’¡ **Key Insight:** 

*This marks a fundamental shift in how models are trained â€” **targeting critical reasoning steps** outperforms brute-force learning, making high-quality AI training achievable even with limited computational resources.*


---


## ğŸ§  Expertise-Driven Contrast

| **Amateur Model** | **Perf. Gap** | **GSM8K** | **MATH** | **SVAMP** | **ASDiv** | **MMLU STEM** | **AVG.** |
|-------------------|-------------|-----------|----------|-----------|-----------|---------------|----------|
| **Expert: <nobr>Qwen2.5-Math-1.5B</nobr>** |||||||||
| **<nobr>Qwen2.5-0.5B</nobr>**             | **38.2**  | **70.6** | **59.3** | **76.0** | **79.8** | **54.9** | **68.1** |
| <nobr>Qwen2.5-1.5B</nobr>                 | 35.1  | 63.4 | 57.1 | 69.7 | 75.7 | 54.8 | 64.1 |
| <nobr>Qwen2.5-Math-1.5B</nobr>            | /  | / | / | / | / | / | / |
| <nobr>Qwen2.5-Math-1.5B-Ins</nobr>        | -42.3 | 41.4 | 35.5 | 67.5 | 66.4 | 55.0 | 53.2 |
| *Expert Only (Baseline)*                  | /     | 42.5 | 34.2 | 68.8 | 68.1 | 49.8 | 52.7 |
| **Expert: <nobr>Qwen2.5-Math-7B</nobr>** |||||||||
| **<nobr>Qwen2.5-0.5B</nobr>**             | **53.2**  | **67.9** | **57.8** | **77.2** | **80.6** | **70.5** | **70.8** |
| <nobr>Qwen2.5-1.5B</nobr>                 | 50.1  | 69.0 | 56.0 | 77.6 | 78.9 | 69.5 | 70.2 |
| <nobr>Qwen2.5-Math-1.5B</nobr>            | 15.0  | 56.9 | 50.2 | 63.5 | 63.4 | 70.7 | 60.9 |
| <nobr>Qwen2.5-Math-1.5B-Ins</nobr>        | -27.3 | 59.4 | 49.0 | 68.3 | 69.6 | 70.3 | 63.3 |
| *Expert Only (Baseline)*                  | /     | 57.5 | 51.8 | 67.9 | 72.7 | 69.8 | 63.9 |


- **Domain Expertise over Scale:** *The success of Expertâ€“Amateur collaboration is driven most effectively by domain-specific knowledge rather than model size (e.g., Qwen2.5-Math-1.5B vs. Qwen2.5-1.5B), freeing LightReasoner from rigid scaling constraints.*

- **Dependence on Expertise Gap:** *Performance gains are closely correlated with the size of the expertise gap â€” as the Amateur approaches the Expertâ€™s capability, contrastive signals weaken and improvements diminish.*


---

## ğŸ” More Insights

<p align="center">
  <img src="./assets/gap_vs_perf.png" alt="Sampling Stage" width="55.5%"/>
  <img src="./assets/radar_ablations.png" alt="Fine-tuning Stage" width="34.5%"/>
</p>

<p align="center">
  
  <em>ğŸ‘ˆ Figure 4(a): Expertâ€“Amateur Pairing Effects â€” Each point represents a fixed Expert model paired with an Amateur model. The performance gains achieved by LightReasoner diminish as the expertise gap narrows.</em><br>

  <em>ğŸ‘‰ Figure 4(b): Impact of Ablation â€” Removing key components from LightReasoner consistently reduces performance, revealing their critical contributions.</em>

</p>


---


## ğŸ† Comparison with Competing Methods

<table>
<tr>
<td>

<!-- Left Table -->
  
| **Attribute**        | **Time** | **SFT** | **LightR** |
|-----------------------|----------------|---------|------------|
| Full trajectories     | â¬†ï¸          | âœ…      | âŒ         |
| All-token tuning      | â¬†ï¸          | âœ…      | âŒ         |
| Prefix termination    | â¬‡ï¸          | âŒ      | âœ…         |
| Selective tokens      | â¬‡ï¸          | âŒ      | âœ…         |
| Verification-free     | â¬‡ï¸          | âŒ      | âœ…         |

</td>
<td>

<!-- Right Table -->

| **Attribute**         | **Utility** | **CD**      | **LightR** |
|------------------------|------------------|-------------|------------|
| Contrast usage         | /                | Inference   | Training   |
| Size-based contrast    | â¬‡ï¸            | âœ…          | âŒ         |
| Expertise contrast     | â¬†ï¸            | âŒ          | âœ…         |
| Persistent benefits    | â¬†ï¸            | âŒ          | âœ…         |
| Standalone inference  | â¬†ï¸            | âŒ          | âœ…         |

</td>
</tr>
</table>

- ğŸ‘ˆ *Left:* Efficiency contrasts at a glance. â¬†ï¸ and â¬‡ï¸ indicate whether each aspect helps or hurts the overall efficiency of the method. 
  
- ğŸ‘‰ *Right:* Key differences between traditional Contrastive Decoding (CD) methods and LightReasoner. â¬†ï¸ and â¬‡ï¸ indicate whether each aspect helps or hurts the practicality of the method.


---


## â˜•ï¸ Citation

If you find this work useful, please consider citing our paper:

```python
@article{wang2025lightreasoner,
  title={LightReasoner: Can Small Language Models Teach Large Language Models Reasoning?},
  author={Wang, Jingyuan and Chen, Yankai and Li, Zhonghang and Huang, Chao},
  journal={arXiv preprint arXiv:2510.07962},
  year={2025}
}
```

Thank you for your interest in our work!


---


## ğŸ“œ License

This project is released under the [MIT License](./LICENSE).

